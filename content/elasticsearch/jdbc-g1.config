#全量更新，第一次导入mysql数据时使用
input {
  jdbc {
    jdbc_driver_library => "/opt/logstash/mysql-connector-java-5.1.43/mysql-connector-java-5.1.43-bin.jar"
    jdbc_driver_class => "com.mysql.jdbc.Driver"
    jdbc_connection_string => "jdbc:mysql://139.196.16.67:3306/whateat?useUnicode=true&characterEncoding=utf-8"
    jdbc_user => "root"
    jdbc_password => "TYwy2016720"
    schedule => "* * * * *"

	clean_run => false  #重置sql_last_value为0

	#是否记录上次执行结果, 如果为真,将会把上次执行到的 tracking_column 字段的值记录下来,保存到 last_run_metadata_path 指定的文件中
	record_last_run => true
	last_run_metadata_path => "/var/tmp/last_run_value.last"

	#是否需要记录某个column 的值,如果 record_last_run 为真,可以自定义我们需要 track 的 column 名称，此时该参数就要为 true. 否则默认 track 的是 timestamp 的值.
	use_column_value => true #即如果设置为true的话，sql_last_value为上一次更新的最后时刻值,false默认值default是now()当前时间
	#如果 use_column_value 为真,需配置此参数. track 的数据库 column 名,该 column 必须是递增的.比如：ID.
	tracking_column => "id" #记录的值
	tracking_column_type => "numeric"

	jdbc_paging_enabled => "true"
	jdbc_page_size => 500  #每次更新500条数据
	jdbc_fetch_size => 500 
    statement => "select * from anote where  cateid=31 AND  id>= :sql_last_value" 
	#SELECT * FROM (select * from anote where  cateid=31 AND  id>= '2017-09-05 02:05:00') AS `t1` LIMIT 1 OFFSET 143

    type => "table_anote"
  }
  # add more jdbc inputs to suit your needs 
}
output {
	stdout {
        codec => json_lines
    }

	if[type] == "table_anote"{
        elasticsearch {
        hosts  => "localhost:9200"
        index => "db_whateat"
        document_type => "%{type}" # <- use the type from each input
        document_id => "%{id}" #防止数据重复
        }
    }

  
}
